{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_v2_s(weights=None)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.convnext_tiny(weights=None)\n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/tho121/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(model.heads[0].in_features, model.heads[0].in_features),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(model.heads[0].in_features, num_classes)\n",
    ")\n",
    "\n",
    "model.heads = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.swin_v2_t(weights=torchvision.models.Swin_V2_T_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(model.head.in_features, model.head.in_features),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(model.head.in_features, num_classes)\n",
    ")\n",
    "\n",
    "model.head = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        #transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomCrop(224, 64),\n",
    "        transforms.RandomRotation((-90,90)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset/train'\n",
    "train_image_datasets = datasets.ImageFolder(train_dir, train_transforms)\n",
    "\n",
    "val_dir = 'dataset/val'\n",
    "val_image_datasets = datasets.ImageFolder(val_dir, test_transforms)\n",
    "\n",
    "test_dir = 'dataset/test'\n",
    "test_image_datasets = datasets.ImageFolder(test_dir, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efficientnet_v2_s = 32\n",
    "#vit_b_16 = 24\n",
    "\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_image_datasets,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=2)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_image_datasets,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_image_datasets,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3404 Acc: 0.8596\n",
      "train Loss: 0.1959 Acc: 0.9121\n",
      "train Loss: 0.1782 Acc: 0.9242\n",
      "train Loss: 0.1626 Acc: 0.9317\n",
      "train Loss: 0.1467 Acc: 0.9388\n",
      "val Loss: 0.0819 Acc: 0.9633\n",
      "train Loss: 0.1443 Acc: 0.9438\n",
      "train Loss: 0.1518 Acc: 0.9304\n",
      "train Loss: 0.1341 Acc: 0.9463\n",
      "train Loss: 0.1207 Acc: 0.9483\n",
      "train Loss: 0.1278 Acc: 0.9504\n",
      "val Loss: 0.0735 Acc: 0.9700\n",
      "train Loss: 0.1323 Acc: 0.9446\n",
      "train Loss: 0.1375 Acc: 0.9471\n",
      "train Loss: 0.1074 Acc: 0.9592\n",
      "train Loss: 0.1119 Acc: 0.9492\n",
      "train Loss: 0.1192 Acc: 0.9450\n",
      "val Loss: 0.0692 Acc: 0.9700\n",
      "Saving at epoch: 14.0\n",
      "train Loss: 0.1135 Acc: 0.9567\n",
      "train Loss: 0.1174 Acc: 0.9521\n",
      "train Loss: 0.1136 Acc: 0.9563\n",
      "train Loss: 0.1106 Acc: 0.9550\n",
      "train Loss: 0.1147 Acc: 0.9513\n",
      "val Loss: 0.0505 Acc: 0.9833\n",
      "Saving at epoch: 19.0\n",
      "train Loss: 0.1090 Acc: 0.9508\n",
      "train Loss: 0.1095 Acc: 0.9554\n",
      "train Loss: 0.1166 Acc: 0.9500\n",
      "train Loss: 0.1093 Acc: 0.9550\n",
      "train Loss: 0.0996 Acc: 0.9596\n",
      "val Loss: 0.0841 Acc: 0.9767\n",
      "train Loss: 0.1063 Acc: 0.9588\n",
      "train Loss: 0.1019 Acc: 0.9629\n",
      "train Loss: 0.0956 Acc: 0.9646\n",
      "train Loss: 0.1005 Acc: 0.9596\n",
      "train Loss: 0.0907 Acc: 0.9596\n",
      "val Loss: 0.0510 Acc: 0.9900\n",
      "Saving at epoch: 29.0\n",
      "train Loss: 0.0964 Acc: 0.9621\n",
      "train Loss: 0.1100 Acc: 0.9554\n",
      "train Loss: 0.0934 Acc: 0.9621\n",
      "train Loss: 0.1008 Acc: 0.9608\n",
      "train Loss: 0.0980 Acc: 0.9592\n",
      "val Loss: 0.0474 Acc: 0.9800\n",
      "train Loss: 0.0866 Acc: 0.9679\n",
      "train Loss: 0.0881 Acc: 0.9638\n",
      "train Loss: 0.0888 Acc: 0.9679\n",
      "train Loss: 0.0984 Acc: 0.9608\n",
      "train Loss: 0.0973 Acc: 0.9554\n",
      "val Loss: 0.0464 Acc: 0.9800\n",
      "train Loss: 0.1025 Acc: 0.9596\n",
      "train Loss: 0.0906 Acc: 0.9638\n",
      "train Loss: 0.0993 Acc: 0.9613\n",
      "train Loss: 0.0951 Acc: 0.9638\n",
      "train Loss: 0.0861 Acc: 0.9663\n",
      "val Loss: 0.0447 Acc: 0.9733\n",
      "train Loss: 0.0878 Acc: 0.9646\n",
      "train Loss: 0.0894 Acc: 0.9650\n",
      "train Loss: 0.0871 Acc: 0.9621\n",
      "train Loss: 0.0844 Acc: 0.9671\n",
      "train Loss: 0.0906 Acc: 0.9654\n",
      "val Loss: 0.0576 Acc: 0.9800\n",
      "train Loss: 0.0946 Acc: 0.9613\n",
      "train Loss: 0.0820 Acc: 0.9671\n",
      "train Loss: 0.0870 Acc: 0.9700\n",
      "train Loss: 0.0814 Acc: 0.9654\n",
      "train Loss: 0.0950 Acc: 0.9654\n",
      "val Loss: 0.0395 Acc: 0.9867\n",
      "train Loss: 0.0847 Acc: 0.9646\n",
      "train Loss: 0.0784 Acc: 0.9675\n",
      "train Loss: 0.0840 Acc: 0.9654\n",
      "train Loss: 0.0740 Acc: 0.9704\n",
      "train Loss: 0.0899 Acc: 0.9650\n",
      "val Loss: 0.0441 Acc: 0.9767\n",
      "train Loss: 0.0997 Acc: 0.9596\n",
      "train Loss: 0.0824 Acc: 0.9671\n",
      "train Loss: 0.0770 Acc: 0.9700\n",
      "train Loss: 0.0757 Acc: 0.9638\n",
      "train Loss: 0.0726 Acc: 0.9708\n",
      "val Loss: 0.0369 Acc: 0.9867\n",
      "train Loss: 0.0786 Acc: 0.9671\n",
      "train Loss: 0.0852 Acc: 0.9696\n",
      "train Loss: 0.0815 Acc: 0.9671\n",
      "train Loss: 0.0710 Acc: 0.9729\n",
      "train Loss: 0.0845 Acc: 0.9679\n",
      "val Loss: 0.0349 Acc: 0.9800\n",
      "train Loss: 0.0782 Acc: 0.9704\n",
      "train Loss: 0.0718 Acc: 0.9696\n",
      "train Loss: 0.0702 Acc: 0.9696\n",
      "train Loss: 0.0761 Acc: 0.9713\n",
      "train Loss: 0.0803 Acc: 0.9658\n",
      "val Loss: 0.0434 Acc: 0.9800\n",
      "train Loss: 0.0813 Acc: 0.9663\n",
      "train Loss: 0.0717 Acc: 0.9708\n",
      "train Loss: 0.0757 Acc: 0.9696\n",
      "train Loss: 0.0713 Acc: 0.9725\n",
      "train Loss: 0.0734 Acc: 0.9646\n",
      "val Loss: 0.0460 Acc: 0.9800\n",
      "train Loss: 0.0718 Acc: 0.9750\n",
      "train Loss: 0.0745 Acc: 0.9713\n",
      "train Loss: 0.0777 Acc: 0.9725\n",
      "train Loss: 0.0720 Acc: 0.9725\n",
      "train Loss: 0.0761 Acc: 0.9708\n",
      "val Loss: 0.1048 Acc: 0.9633\n",
      "train Loss: 0.0664 Acc: 0.9725\n",
      "train Loss: 0.0725 Acc: 0.9721\n",
      "train Loss: 0.0675 Acc: 0.9729\n",
      "train Loss: 0.0832 Acc: 0.9708\n",
      "train Loss: 0.0620 Acc: 0.9758\n",
      "val Loss: 0.0471 Acc: 0.9800\n",
      "train Loss: 0.0711 Acc: 0.9667\n",
      "train Loss: 0.0724 Acc: 0.9729\n",
      "train Loss: 0.0693 Acc: 0.9738\n",
      "train Loss: 0.0686 Acc: 0.9733\n",
      "train Loss: 0.0856 Acc: 0.9646\n",
      "val Loss: 0.0615 Acc: 0.9767\n",
      "train Loss: 0.0589 Acc: 0.9771\n",
      "train Loss: 0.0756 Acc: 0.9692\n",
      "train Loss: 0.0680 Acc: 0.9758\n",
      "train Loss: 0.0681 Acc: 0.9738\n",
      "train Loss: 0.0752 Acc: 0.9713\n",
      "val Loss: 0.0453 Acc: 0.9767\n",
      "train Loss: 0.0695 Acc: 0.9721\n",
      "train Loss: 0.0658 Acc: 0.9746\n",
      "train Loss: 0.0728 Acc: 0.9742\n",
      "train Loss: 0.0768 Acc: 0.9692\n",
      "train Loss: 0.0702 Acc: 0.9713\n",
      "val Loss: 0.0449 Acc: 0.9833\n",
      "train Loss: 0.0555 Acc: 0.9763\n",
      "train Loss: 0.0695 Acc: 0.9717\n",
      "train Loss: 0.0585 Acc: 0.9775\n",
      "train Loss: 0.0866 Acc: 0.9708\n",
      "train Loss: 0.0662 Acc: 0.9700\n",
      "val Loss: 0.0331 Acc: 0.9833\n",
      "train Loss: 0.0705 Acc: 0.9729\n",
      "train Loss: 0.0722 Acc: 0.9708\n",
      "train Loss: 0.0610 Acc: 0.9754\n",
      "train Loss: 0.0679 Acc: 0.9783\n",
      "train Loss: 0.0747 Acc: 0.9708\n",
      "val Loss: 0.0363 Acc: 0.9833\n",
      "train Loss: 0.0747 Acc: 0.9679\n",
      "train Loss: 0.0692 Acc: 0.9725\n",
      "train Loss: 0.0569 Acc: 0.9746\n",
      "train Loss: 0.0675 Acc: 0.9725\n",
      "train Loss: 0.0689 Acc: 0.9717\n",
      "val Loss: 0.0355 Acc: 0.9800\n",
      "train Loss: 0.0738 Acc: 0.9725\n",
      "train Loss: 0.0658 Acc: 0.9725\n",
      "train Loss: 0.0567 Acc: 0.9779\n",
      "train Loss: 0.0488 Acc: 0.9804\n",
      "train Loss: 0.0683 Acc: 0.9733\n",
      "val Loss: 0.0350 Acc: 0.9800\n",
      "train Loss: 0.0576 Acc: 0.9771\n",
      "train Loss: 0.0656 Acc: 0.9746\n",
      "train Loss: 0.0617 Acc: 0.9742\n",
      "train Loss: 0.0481 Acc: 0.9804\n",
      "train Loss: 0.0619 Acc: 0.9742\n",
      "val Loss: 0.0403 Acc: 0.9833\n",
      "train Loss: 0.0736 Acc: 0.9742\n",
      "train Loss: 0.0563 Acc: 0.9779\n",
      "train Loss: 0.0719 Acc: 0.9704\n",
      "train Loss: 0.0497 Acc: 0.9813\n",
      "train Loss: 0.0485 Acc: 0.9821\n",
      "val Loss: 0.0408 Acc: 0.9867\n",
      "train Loss: 0.0536 Acc: 0.9783\n",
      "train Loss: 0.0568 Acc: 0.9775\n",
      "train Loss: 0.0677 Acc: 0.9758\n",
      "train Loss: 0.0631 Acc: 0.9754\n",
      "train Loss: 0.0632 Acc: 0.9758\n",
      "val Loss: 0.0523 Acc: 0.9767\n",
      "train Loss: 0.0647 Acc: 0.9750\n",
      "train Loss: 0.0529 Acc: 0.9738\n",
      "train Loss: 0.0683 Acc: 0.9750\n",
      "train Loss: 0.0638 Acc: 0.9767\n",
      "train Loss: 0.0531 Acc: 0.9788\n",
      "val Loss: 0.0449 Acc: 0.9800\n",
      "train Loss: 0.0576 Acc: 0.9796\n",
      "train Loss: 0.0616 Acc: 0.9771\n",
      "train Loss: 0.0560 Acc: 0.9771\n",
      "train Loss: 0.0587 Acc: 0.9767\n",
      "train Loss: 0.0501 Acc: 0.9792\n",
      "val Loss: 0.0424 Acc: 0.9800\n",
      "train Loss: 0.0603 Acc: 0.9771\n",
      "train Loss: 0.0534 Acc: 0.9758\n",
      "train Loss: 0.0525 Acc: 0.9813\n",
      "train Loss: 0.0561 Acc: 0.9771\n",
      "train Loss: 0.0385 Acc: 0.9854\n",
      "val Loss: 0.0237 Acc: 0.9867\n",
      "train Loss: 0.0498 Acc: 0.9813\n",
      "train Loss: 0.0487 Acc: 0.9838\n",
      "train Loss: 0.0369 Acc: 0.9863\n",
      "train Loss: 0.0394 Acc: 0.9833\n",
      "train Loss: 0.0415 Acc: 0.9829\n",
      "val Loss: 0.0584 Acc: 0.9767\n",
      "train Loss: 0.0459 Acc: 0.9821\n",
      "train Loss: 0.0419 Acc: 0.9867\n",
      "train Loss: 0.0466 Acc: 0.9825\n",
      "train Loss: 0.0424 Acc: 0.9817\n",
      "train Loss: 0.0358 Acc: 0.9850\n",
      "val Loss: 0.0337 Acc: 0.9867\n",
      "train Loss: 0.0525 Acc: 0.9813\n",
      "train Loss: 0.0412 Acc: 0.9825\n",
      "train Loss: 0.0521 Acc: 0.9796\n",
      "train Loss: 0.0397 Acc: 0.9808\n",
      "train Loss: 0.0428 Acc: 0.9863\n",
      "val Loss: 0.0425 Acc: 0.9733\n",
      "train Loss: 0.0497 Acc: 0.9804\n",
      "train Loss: 0.0457 Acc: 0.9808\n",
      "train Loss: 0.0491 Acc: 0.9800\n",
      "train Loss: 0.0561 Acc: 0.9788\n",
      "train Loss: 0.0497 Acc: 0.9783\n",
      "val Loss: 0.0244 Acc: 0.9867\n",
      "train Loss: 0.0416 Acc: 0.9867\n",
      "train Loss: 0.0525 Acc: 0.9788\n",
      "train Loss: 0.0516 Acc: 0.9800\n",
      "train Loss: 0.0494 Acc: 0.9838\n",
      "train Loss: 0.0540 Acc: 0.9813\n",
      "val Loss: 0.0332 Acc: 0.9833\n",
      "train Loss: 0.0406 Acc: 0.9867\n",
      "train Loss: 0.0368 Acc: 0.9875\n",
      "train Loss: 0.0441 Acc: 0.9833\n",
      "train Loss: 0.0606 Acc: 0.9742\n",
      "train Loss: 0.0430 Acc: 0.9821\n",
      "val Loss: 0.0518 Acc: 0.9800\n",
      "train Loss: 0.0372 Acc: 0.9858\n",
      "train Loss: 0.0395 Acc: 0.9854\n",
      "train Loss: 0.0383 Acc: 0.9879\n",
      "train Loss: 0.0449 Acc: 0.9833\n",
      "train Loss: 0.0372 Acc: 0.9858\n",
      "val Loss: 0.0391 Acc: 0.9867\n",
      "train Loss: 0.0443 Acc: 0.9804\n",
      "train Loss: 0.0423 Acc: 0.9846\n",
      "train Loss: 0.0403 Acc: 0.9858\n",
      "train Loss: 0.0418 Acc: 0.9808\n",
      "train Loss: 0.0383 Acc: 0.9842\n",
      "val Loss: 0.0409 Acc: 0.9833\n",
      "train Loss: 0.0381 Acc: 0.9863\n",
      "train Loss: 0.0355 Acc: 0.9854\n",
      "train Loss: 0.0407 Acc: 0.9850\n",
      "train Loss: 0.0439 Acc: 0.9821\n",
      "train Loss: 0.0322 Acc: 0.9879\n",
      "val Loss: 0.0413 Acc: 0.9800\n",
      "finished\n",
      "Best epoch: 29.0\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=0.0005) #effnet, vit = 0.0005\n",
    "criteron = nn.CrossEntropyLoss()\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
    "\n",
    "writer = SummaryWriter('output')\n",
    "\n",
    "# let's train it for 10 epochs\n",
    "num_epochs = 200\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = train_loader\n",
    "dataloaders['val'] = val_loader\n",
    "\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(train_image_datasets)\n",
    "dataset_sizes['val'] = len(val_image_datasets)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            if (epoch+1) % 5 > 0:  #only every 5 epochs\n",
    "                continue\n",
    "\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criteron(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step(loss.item)\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        if phase == 'train':\n",
    "            writer.add_scalar('training loss', epoch_loss, epoch)\n",
    "            writer.add_scalar('training acc', epoch_acc, epoch)\n",
    "            lr_scheduler.step(epoch_loss)\n",
    "        elif phase == 'val':\n",
    "            writer.add_scalar('val loss', epoch_loss, epoch)\n",
    "            writer.add_scalar('val acc', epoch_acc, epoch)\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        # save best model\n",
    "        if epoch > 10 and phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            print(\"Saving at epoch: %.1f\" % (epoch))\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), 'best_checkpoint.pt')\n",
    "\n",
    "print(\"finished\")\n",
    "writer.close()\n",
    "torch.save(model.state_dict(), 'final_checkpoint.pt')\n",
    "print(\"Best epoch: %.1f\" % (best_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46f2e51145526f0bdd28d5f0075079de9471b9ab1aeb1a8ffd81fe5cc809b6a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
